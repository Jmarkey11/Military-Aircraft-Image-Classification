{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set class count: 81 / 81 classes\n",
      "\n",
      "Val set class count: 81 / 81 classes\n",
      "\n",
      "Test set class count: 81 / 81 classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 24160/24160 [03:21<00:00, 120.05it/s]\n",
      "Processing val: 100%|██████████| 5177/5177 [01:57<00:00, 44.07it/s] \n",
      "Processing test: 100%|██████████| 5178/5178 [01:48<00:00, 47.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All splits with stacked tensors saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# === 1. Path setup ===\n",
    "path = \"C:/Users/jono_/.cache/kagglehub/datasets/a2015003713/militaryaircraftdetectiondataset/versions/86/crop\"\n",
    "\n",
    "# === 2. Collect image paths and labels ===\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for folder in os.listdir(path):\n",
    "    folder_path = os.path.join(path, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for image in os.listdir(folder_path):\n",
    "            if image.endswith(\".jpg\"):\n",
    "                images.append(os.path.join(folder_path, image))\n",
    "                labels.append(folder)\n",
    "\n",
    "# Convert to arrays for indexing\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Save to CSV for reference\n",
    "pd.DataFrame({\"images\": images, \"labels\": labels}).to_csv(\n",
    "    \"military_aircraft_crop.csv\", index=False\n",
    ")\n",
    "\n",
    "# === 3. Define Transforms ===\n",
    "mean = [0.4913, 0.5240, 0.5560]\n",
    "std = [0.1958, 0.1944, 0.1987]\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_eval = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# === 4. Stratified Train/Val/Test Split ===\n",
    "sss_1 = StratifiedShuffleSplit(n_splits=1, test_size=0.30, random_state=42)\n",
    "train_idx, temp_idx = next(sss_1.split(images, labels))\n",
    "\n",
    "sss_2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "val_idx, test_idx = next(sss_2.split(images[temp_idx], labels[temp_idx]))\n",
    "\n",
    "val_idx = temp_idx[val_idx]\n",
    "test_idx = temp_idx[test_idx]\n",
    "\n",
    "# === 5. Sanity check: ensure classes are covered in all splits ===\n",
    "def check_class_coverage(idxs, labels, name):\n",
    "    subset_labels = labels[idxs]\n",
    "    class_counts = Counter(subset_labels)\n",
    "    print(f\"\\n{name} set class count: {len(class_counts)} / {len(set(labels))} classes\")\n",
    "    rare = [cls for cls, count in class_counts.items() if count < 3]\n",
    "    if rare:\n",
    "        print(f\"⚠️ Rare classes with <3 samples in {name}: {rare}\")\n",
    "\n",
    "check_class_coverage(train_idx, labels, \"Train\")\n",
    "check_class_coverage(val_idx, labels, \"Val\")\n",
    "check_class_coverage(test_idx, labels, \"Test\")\n",
    "\n",
    "# === 6. Helper to apply transform and save ===\n",
    "def transform_and_save(name, idxs, transform):\n",
    "    transformed_images = []\n",
    "    transformed_labels = []\n",
    "\n",
    "    for i in tqdm(idxs, desc=f\"Processing {name}\"):\n",
    "        try:\n",
    "            img_path = images[i]\n",
    "            label = labels[i]\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            image_tensor = transform(image)\n",
    "            transformed_images.append(image_tensor)\n",
    "            transformed_labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Skipping {images[i]} due to error: {e}\")\n",
    "\n",
    "    # Stack image tensors into one big tensor [N, 3, 224, 224]\n",
    "    image_tensor_stack = torch.stack(transformed_images)\n",
    "\n",
    "    # Save as dict\n",
    "    torch.save(\n",
    "        {\"tensors\": image_tensor_stack, \"labels\": transformed_labels},\n",
    "        f\"military_aircraft_crop_{name}.pt\",\n",
    "    )\n",
    "\n",
    "# === 7. Process and save each split ===\n",
    "transform_and_save(\"train\", train_idx, transform_train)\n",
    "transform_and_save(\"val\", val_idx, transform_eval)\n",
    "transform_and_save(\"test\", test_idx, transform_eval)\n",
    "\n",
    "print(\"✅ All splits with stacked tensors saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
